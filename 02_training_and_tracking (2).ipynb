{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94f837ad-9fe6-4355-85a1-4d9faf77a082",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Model Training - AutoML & Manual Training\n",
    "Demonstrate MLflow experiment tracking with both approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8ae2405-c5f5-40da-a962-13ce3c45dbab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "mlflow.sklearn.autolog(log_input_examples=True, log_model_signatures=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c317d78b-a2f7-4a6d-88cb-69b9fb362159",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model Training - Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdcafcce-e82d-4371-bd1c-39732633b752",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "577b1ee7-5430-4cc8-bac9-fe751776609b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (100, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fe = FeatureEngineeringClient()\n",
    "features_df = fe.read_table(name=\"main.ttw_workshop_demo.customer_features\")\n",
    "\n",
    "# Convert to pandas for training\n",
    "training_data = features_df.toPandas()\n",
    "feature_cols = [\n",
    "    'days_since_login', 'Ebooks_Downloaded_6_Months', 'Average_Session_Time',\n",
    "    'Days_Since_Last_Activity', 'engagement_score', 'subscription_tier_numeric'\n",
    "]\n",
    "X = training_data[feature_cols].fillna(0)\n",
    "\n",
    "# Save training dataset (dbdemos pattern)\n",
    "training_spark_df = spark.createDataFrame(training_data)\n",
    "training_spark_df.write.mode(\"overwrite\").saveAsTable(\"main.ttw_workshop_demo.training_dataset\")\n",
    "\n",
    "print(f\"Training data shape: {X.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e6ed213-0525-4d7f-80c6-dc8046587592",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 80, Testing: 20\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26438269d274ee888256f271470913c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n/databricks/python/lib/python3.11/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2089788cb9b54992830de32a4ec25842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'main.ttw_workshop_demo.customer_anomaly_detector' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd34b5647f74b03b875967c081be6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'main.ttw_workshop_demo.customer_anomaly_detector'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Isolation Forest: 0 anomalies detected\n\uD83C\uDFC3 View run isolation_forest_v1 at: https://e2-demo-west.cloud.databricks.com/ml/experiments/30434066767557/runs/dbdc5c9dfd77461187d2887a756941d4\n\uD83E\uDDEA View experiment at: https://e2-demo-west.cloud.databricks.com/ml/experiments/30434066767557\n"
     ]
    }
   ],
   "source": [
    "# Track the run with MLflow\n",
    "experiment_path = \"/Users/tingting.wan@databricks.com/anomaly_demo_qs\"\n",
    "mlflow.set_experiment(experiment_path)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "print(f\"Training: {X_train.shape[0]}, Testing: {X_test.shape[0]}\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"isolation_forest\") as run:\n",
    "    # Log parameters\n",
    "    mlflow.set_tag(\"role\", \"champion\")\n",
    "    mlflow.log_param(\"algorithm\", \"IsolationForest\")\n",
    "    mlflow.log_param(\"contamination\", 0.05)\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('isolation_forest', IsolationForest(\n",
    "            contamination=0.05,\n",
    "            random_state=42,\n",
    "            n_estimators=100\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Train model\n",
    "    pipeline.fit(X_train)\n",
    "    \n",
    "    # Predictions and scoring\n",
    "    train_predictions = pipeline.predict(X_train)\n",
    "    test_predictions = pipeline.predict(X_test)\n",
    "    train_scores = pipeline.decision_function(X_train)\n",
    "    test_scores = pipeline.decision_function(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_anomaly_count = np.sum(train_predictions == -1)\n",
    "    test_anomaly_count = np.sum(test_predictions == -1)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"train_anomaly_count\", train_anomaly_count)\n",
    "    mlflow.log_metric(\"test_anomaly_count\", test_anomaly_count)\n",
    "    mlflow.log_metric(\"train_anomaly_rate\", train_anomaly_count / len(X_train))\n",
    "    mlflow.log_metric(\"test_anomaly_rate\", test_anomaly_count / len(X_test))\n",
    "    \n",
    "    # Register model\n",
    "    model_name = \"main.ttw_workshop_demo.customer_anomaly_detector\"\n",
    "    mlflow.sklearn.log_model(\n",
    "        pipeline,\n",
    "        \"model\",\n",
    "        registered_model_name=model_name,\n",
    "        input_example=X_train.head(5)\n",
    "    )\n",
    "    \n",
    "    isolation_run_id = run.info.run_id\n",
    "    print(f\"✅ Isolation Forest: {test_anomaly_count} anomalies detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c9e2972-d3f0-47aa-90ae-c607d342f317",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model Training - PCA (Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7a4b90d-bf0a-4b73-8b23-73f4da8442c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bd58d204a9454bbf388f2cdfe05fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33cc4a6d85ba405d9f3083955bc659ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'main.ttw_workshop_demo.pca_anomaly_detector' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3f977314454737881c68668da5523e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'main.ttw_workshop_demo.pca_anomaly_detector'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PCA Model: 1 anomalies detected\n\uD83C\uDFC3 View run pca_reconstruction_v1 at: https://e2-demo-west.cloud.databricks.com/ml/experiments/30434066767557/runs/c341e8d9d1cd470bafcdaea457196d0c\n\uD83E\uDDEA View experiment at: https://e2-demo-west.cloud.databricks.com/ml/experiments/30434066767557\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"pca_reconstruction\") as run:\n",
    "    # Log parameters\n",
    "    mlflow.set_tag(\"role\", \"challenger\")\n",
    "    mlflow.log_param(\"algorithm\", \"PCA\")\n",
    "    mlflow.log_param(\"n_components\", 3)\n",
    "    \n",
    "    # PCA pipeline\n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA(n_components=3)\n",
    "    \n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_train_reconstructed = pca.inverse_transform(X_train_pca)\n",
    "    \n",
    "    # Calculate reconstruction errors\n",
    "    train_errors = np.sum((X_train_scaled - X_train_reconstructed) ** 2, axis=1)\n",
    "    threshold = np.percentile(train_errors, 95)\n",
    "    \n",
    "    # Test predictions\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "    X_test_reconstructed = pca.inverse_transform(X_test_pca)\n",
    "    test_errors = np.sum((X_test_scaled - X_test_reconstructed) ** 2, axis=1)\n",
    "    \n",
    "    test_anomalies = np.sum(test_errors > threshold)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"test_anomaly_count\", test_anomalies)\n",
    "    mlflow.log_metric(\"test_anomaly_rate\", test_anomalies / len(X_test))\n",
    "    mlflow.log_metric(\"explained_variance_ratio\", pca.explained_variance_ratio_.sum())\n",
    "    \n",
    "    # Create and register pipeline\n",
    "    pca_pipeline = Pipeline([('scaler', scaler), ('pca', pca)])\n",
    "    pca_model_name = \"main.ttw_workshop_demo.pca_anomaly_detector\"\n",
    "    \n",
    "    # For PCA model signature\n",
    "    pca_sample_output = pca_pipeline.transform(X_train.head(5))\n",
    "    pca_signature = infer_signature(X_train.head(5), pca_sample_output)\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        pca_pipeline,\n",
    "        \"model\", \n",
    "        registered_model_name=pca_model_name,\n",
    "        input_example=X_train.head(5),\n",
    "        signature=pca_signature\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ PCA Model: {test_anomalies} anomalies detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93d752f9-15ef-42fd-a9fc-0cc63e993dc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>run_id</th><th>role</th><th>anomaly_rate</th></tr></thead><tbody><tr><td>c341e8d9d1cd470bafcdaea457196d0c</td><td>challenger</td><td>0.05</td></tr><tr><td>dbdc5c9dfd77461187d2887a756941d4</td><td>champion</td><td>0.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "c341e8d9d1cd470bafcdaea457196d0c",
         "challenger",
         0.05
        ],
        [
         "dbdc5c9dfd77461187d2887a756941d4",
         "champion",
         0.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "run_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "role",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "anomaly_rate",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Champion vs Challenger in MLflow UI\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "exp = mlflow.get_experiment_by_name(experiment_path)\n",
    "runs = client.search_runs(\n",
    "    [exp.experiment_id],\n",
    "    filter_string=\"tags.role IN ('champion','challenger')\",\n",
    "    order_by=[\"start_time DESC\"]\n",
    ")\n",
    "# Display role, run_id, and key metrics\n",
    "display(\n",
    "    pd.DataFrame([{\n",
    "        \"run_id\": r.info.run_id,\n",
    "        \"role\": r.data.tags.get(\"role\"),\n",
    "        \"anomaly_rate\": r.data.metrics.get(\"test_anomaly_rate\")\n",
    "    } for r in runs])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f01ca1a1-0873-4e81-91e3-8f3b022b38fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## (Optional)AutoML Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "2af50600-a32d-4422-978a-fdc53f4d41ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from databricks.feature_engineering import FeatureEngineeringClient\n",
    "# from datetime import datetime\n",
    "# from databricks import automl\n",
    "# import getpass\n",
    "# fe = FeatureEngineeringClient()\n",
    "# features_df = fe.read_table(name=\"main.ttw_workshop_demo.customer_features\")\n",
    "\n",
    "# # Save training dataset\n",
    "# # 2. DEFINE BINARY TARGET FOR AUTOML\n",
    "# # Anomaly = 1 if 'engagement_score' below 10% quantile, else 0\n",
    "# quantile = features_df.approxQuantile(\"engagement_score\", [0.1], 0.01)[0]\n",
    "# X = features_df.withColumn(\n",
    "#     \"anomaly_target\",\n",
    "#     (F.col(\"engagement_score\") < quantile).cast(\"int\")\n",
    "# )\n",
    "# # 3. TRAIN/TEST SPLIT\n",
    "# # For demo/test only: random split\n",
    "# X = X.withColumn(\"split\", F.when(F.rand() > 0.2, \"train\").otherwise(\"test\"))\n",
    "\n",
    "# # --- Guarantee at least two classes per split for AutoML ---\n",
    "# # Convert to pandas for logic, operate only on 'anomaly_target' and 'split'\n",
    "# X_pd = X.select(\"anomaly_target\", \"split\").toPandas()\n",
    "\n",
    "# for split_val in [\"train\", \"test\"]:\n",
    "#     subset = X_pd[X_pd['split'] == split_val]\n",
    "#     # Only flip if split is nonempty and not yet both classes\n",
    "#     if subset['anomaly_target'].nunique() < 2 and len(subset) > 1:\n",
    "#         first_idx = subset.index[0]\n",
    "#         X_pd.at[first_idx, 'anomaly_target'] = 1 - X_pd.at[first_idx, 'anomaly_target']\n",
    "\n",
    "# # Write updated anomaly_target back to the Spark DataFrame X, in-place with all original columns preserved\n",
    "# X_pd = X_pd.reset_index().rename(columns={\"index\": \"row_idx\"})\n",
    "# X = X.withColumn(\"row_idx\", F.monotonically_increasing_id())\n",
    "# fix_df = spark.createDataFrame(X_pd[[\"row_idx\", \"anomaly_target\"]])\n",
    "# X = X.drop(\"anomaly_target\").join(fix_df, on=\"row_idx\", how=\"left\").drop(\"row_idx\")\n",
    "\n",
    "\n",
    "# X.write.mode(\"overwrite\").saveAsTable(\"main.ttw_workshop_demo.training_dataset_automl_w_target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "8e70dacd-579b-4d62-8e58-ee7854c1654a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/04 10:55:19 INFO databricks.automl.client.manager: AutoML will optimize for F1 score metric, which is tracked as val_f1_score in the MLflow experiment.\n2025/08/04 10:55:20 INFO databricks.automl.client.manager: MLflow Experiment ID: 30434066767549\n2025/08/04 10:55:20 INFO databricks.automl.client.manager: MLflow Experiment: https://e2-demo-west.cloud.databricks.com/?o=2556758628403379#mlflow/experiments/30434066767549\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83C\uDFC3 View run wise-conch-726 at: https://e2-demo-west.cloud.databricks.com/ml/experiments/30434066767549/runs/79f3545e56d444a49f815468c2370598\n\uD83E\uDDEA View experiment at: https://e2-demo-west.cloud.databricks.com/ml/experiments/30434066767549\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/04 10:56:13 INFO databricks.automl.client.manager: Data exploration notebook: https://e2-demo-west.cloud.databricks.com/?o=2556758628403379#notebook/30434066767554\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ AutoML exception: AutoML experiment failed with error \"Target column must contain at least 2 distinct target classes\". See job run at https://e2-demo-west.cloud.databricks.com/?o=2556758628403379#job/261022380564976/run/352847742545931 for more details.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# xp_path = f\"/Users/tingting.wan@databricks.com/databricks_automl/\"\n",
    "# xp_name = f\"demo_automl_anomaly_{datetime.now().strftime('%Y-%m-%d_%H:%M:%S')}\"\n",
    "\n",
    "# try:\n",
    "#     from databricks import automl\n",
    "\n",
    "#     automl_run = automl.classify(\n",
    "#         experiment_name=xp_name,\n",
    "#         experiment_dir=xp_path,\n",
    "#         dataset=X,\n",
    "#         target_col=\"anomaly_target\",\n",
    "#         split_col=\"split\",\n",
    "#         timeout_minutes=10,\n",
    "#         exclude_cols=[\"Customer_ID\"]  # Remove identifier columns from training\n",
    "#     )\n",
    "#     print(\"✅ AutoML started. Check MLflow for runs.\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"❌ AutoML exception: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39fbfc5d-f867-46ec-b047-8c8159f22b8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02_training_and_tracking",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}